{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hsieh121/generative_ai/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJDLUq9ZYoQF"
      },
      "outputs": [],
      "source": [
        "# Colab ç¨‹å¼ç¢¼å„²å­˜æ ¼\n",
        "!pip install googlemaps gradio transformers torch bitsandbytes accelerate # accelerate å¯èƒ½å°æŸäº›æ¨¡å‹æœ‰å¹«åŠ©"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googlemaps\n",
        "from google.colab import userdata # ç”¨æ–¼è®€å– Colab Secrets\n",
        "\n",
        "# å¾ Colab Secrets è®€å– API Key\n",
        "GMAPS_API_KEY = userdata.get('GMAPS_API_KEY') # å‡è¨­ä½ å°‡é‡‘é‘°å‘½åç‚º GMAPS_API_KEY\n",
        "gmaps = googlemaps.Client(key=GMAPS_API_KEY)\n",
        "\n",
        "def get_restaurant_reviews(restaurant_name, location=\"å°åŒ—å¸‚å¤§å®‰å€\"):\n",
        "    try:\n",
        "        # 1. Text Search (or Find Place) to get place_id\n",
        "        places_result = gmaps.places(query=f\"{restaurant_name} in {location}\")\n",
        "\n",
        "        if not places_result or places_result['status'] != 'OK' or not places_result['results']:\n",
        "            return None, \"æ‰¾ä¸åˆ°é¤å»³æˆ–APIæŸ¥è©¢å¤±æ•—ã€‚\"\n",
        "\n",
        "        place_id = places_result['results'][0]['place_id'] # å–ç¬¬ä¸€å€‹çµæœ\n",
        "        place_name_found = places_result['results'][0]['name']\n",
        "        place_address_found = places_result['results'][0].get('formatted_address', 'åœ°å€æœªæä¾›')\n",
        "        place_rating_found = places_result['results'][0].get('rating', 'è©•åˆ†æœªæä¾›')\n",
        "\n",
        "        # 2. Place Details to get reviews\n",
        "        # language='zh-TW' å˜—è©¦ç²å–ç¹é«”ä¸­æ–‡è©•è«–\n",
        "        details = gmaps.place(place_id=place_id, fields=['name', 'formatted_address', 'rating', 'reviews'], language='zh-TW')\n",
        "\n",
        "        if details['status'] != 'OK':\n",
        "            return None, \"ç²å–é¤å»³è©³ç´°è³‡è¨Šå¤±æ•—ã€‚\"\n",
        "\n",
        "        restaurant_info = {\n",
        "            \"name\": details['result'].get('name', place_name_found),\n",
        "            \"address\": details['result'].get('formatted_address', place_address_found),\n",
        "            \"rating\": details['result'].get('rating', place_rating_found),\n",
        "            \"reviews_text\": []\n",
        "        }\n",
        "\n",
        "        # Places API é€šå¸¸è¿”å›æœ€å¤š 5 æ¢è©•è«–\n",
        "        if 'reviews' in details['result']:\n",
        "            for review in details['result']['reviews']:\n",
        "                restaurant_info[\"reviews_text\"].append(f\"- {review.get('author_name', 'åŒ¿åä½¿ç”¨è€…')} (è©•åˆ†: {review.get('rating', 'N/A')}æ˜Ÿ): {review.get('text', '')}\")\n",
        "\n",
        "        if not restaurant_info[\"reviews_text\"]:\n",
        "             restaurant_info[\"reviews_text\"].append(\"æš«ç„¡è¶³å¤ çš„æ–‡å­—è©•è«–å¯ä¾›åˆ†æã€‚\")\n",
        "\n",
        "        return restaurant_info, None\n",
        "    except Exception as e:\n",
        "        return None, f\"ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\""
      ],
      "metadata": {
        "id": "yFMnRGXyY4Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig # å¼•å…¥ BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# --- ä½ è¦è¼‰å…¥çš„æ¨¡å‹ ID ---\n",
        "model_id = \"google/gemma-7b-it\" # Gemma 7B (éœ€è¦è™•ç†æˆæ¬Šå’Œ HuggingFace Token)\n",
        "\n",
        "model = None  # å…ˆåˆå§‹åŒ–ç‚º None\n",
        "tokenizer = None # å…ˆåˆå§‹åŒ–ç‚º None\n",
        "\n",
        "try:\n",
        "    print(f\"æº–å‚™è¼‰å…¥ã€4-bit é‡åŒ–ã€‘æ¨¡å‹: {model_id}\")\n",
        "    print(f\"æª¢æŸ¥ CUDA æ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}\") # ç¢ºèª CUDA ç’°å¢ƒ\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    # --- è¨­å®š 4-bit é‡åŒ–é…ç½® ---\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",                # æŒ‡å®šé‡åŒ–é¡å‹ï¼Œ\"nf4\" (NormalFloat4) æ˜¯å¸¸ç”¨çš„é¸æ“‡\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,    # è¨­å®šè¨ˆç®—æ™‚ä½¿ç”¨çš„è³‡æ–™é¡å‹ï¼Œbfloat16 å¯æå‡æ•ˆèƒ½\n",
        "                                                  # å¦‚æœä½ çš„ GPU å° bfloat16 æ”¯æ´ä¸ä½³ï¼Œå¯ä»¥æ”¹ç”¨ torch.float16\n",
        "        bnb_4bit_use_double_quant=False           # æ˜¯å¦ä½¿ç”¨é›™é‡é‡åŒ–ï¼Œé€šå¸¸è¨­ç‚º False å³å¯\n",
        "    )\n",
        "\n",
        "    # --- è¼‰å…¥é‡åŒ–æ¨¡å‹ ---\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=quantization_config, # <--- å‚³å…¥é‡åŒ–è¨­å®š\n",
        "        device_map=\"auto\"                        # <--- è®“ Transformers è‡ªå‹•åˆ†é…åˆ° GPU (å¦‚æœå¯ç”¨)\n",
        "    )\n",
        "    print(f\"ã€4-bit é‡åŒ–ã€‘æ¨¡å‹ {model_id} å·²è¼‰å…¥åˆ°è¨­å‚™: {model.device}\")\n",
        "    if hasattr(model, 'get_memory_footprint'): # æª¢æŸ¥æ¨¡å‹ç‰©ä»¶æ˜¯å¦æœ‰ get_memory_footprint æ–¹æ³•\n",
        "        print(f\"æ¨¡å‹è¨˜æ†¶é«”ä½”ç”¨ (è¿‘ä¼¼): {model.get_memory_footprint() / 1024**3:.2f} GB\") # é‡åŒ–å¾Œæ‡‰é å°æ–¼ 14GB\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"è¼‰å…¥ã€4-bit é‡åŒ–ã€‘æ¨¡å‹ {model_id} æ™‚ç™¼ç”ŸéŒ¯èª¤ (å¯èƒ½æ˜¯è³‡æºä¸è¶³ã€éœ€è¦æˆæ¬Šã€æ¨¡å‹åç¨±éŒ¯èª¤æˆ– bitsandbytes æœªæ­£ç¢ºå®‰è£/ç‰ˆæœ¬éèˆŠ): {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc() # æ‰“å°è©³ç´°çš„éŒ¯èª¤å †ç–Š"
      ],
      "metadata": {
        "id": "8Wfe6p4hAKIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llm_output(prompt_text):\n",
        "    if not model or not tokenizer:\n",
        "        return \"LLM æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥ï¼Œç„¡æ³•ç”Ÿæˆæ–‡å­—ã€‚\"\n",
        "    try:\n",
        "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device) # å°‡è¼¸å…¥ç§»è‡³æ¨¡å‹æ‰€åœ¨çš„è¨­å‚™\n",
        "        outputs = model.generate(**inputs, max_new_tokens=250, pad_token_id=tokenizer.eos_token_id) # pad_token_id é¿å…è­¦å‘Š\n",
        "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        #print(f\"DEBUG generate_llm_output: Full decoded result before processing: {result}\") # <--- æ–°å¢\n",
        "        # Gemma æ¨¡å‹çš„å›æ‡‰å¯èƒ½åŒ…å«åŸå§‹ promptï¼Œéœ€è¦è™•ç†\n",
        "        # ç°¡å–®çš„è™•ç†æ–¹å¼æ˜¯ç§»é™¤ prompt_text çš„éƒ¨åˆ†\n",
        "        if result.startswith(prompt_text):\n",
        "             return result[len(prompt_text):].strip()\n",
        "        return result.strip() # ç¢ºä¿ç§»é™¤å‰å¾Œç©ºç™½\n",
        "    except Exception as e:\n",
        "        return f\"LLM ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\"\n",
        "\n",
        "def analyze_reviews_with_llm(reviews_list):\n",
        "    reviews_str = \"\\n\".join(reviews_list)\n",
        "\n",
        "    # 1. è©•è«–ç¸½çµ\n",
        "    prompt_summary = f\"\"\"ä½œç‚ºä¸€å€‹å®¢è§€çš„ç¾é£Ÿè©•è«–åˆ†æå“¡ï¼Œè«‹ä»”ç´°é–±è®€ä»¥ä¸‹é¡§å®¢è©•è«–ã€‚\n",
        "æ ¹æ“šé€™äº›è©•è«–ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡ç‚ºé€™å®¶é¤å»³å¯«ä¸€æ®µç²¾ç°¡çš„æ•´é«”è©•åƒ¹ç¸½çµï¼Œå­—æ•¸ç´„200å­—ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚\n",
        "ç¸½çµæ‡‰æ¶µè“‹é¡§å®¢æåŠçš„ä¸»è¦æ­£é¢å’Œè² é¢é«”é©—ï¼Œå¦‚æœæ²’æœ‰æ˜é¡¯çš„è² é¢é«”é©—ï¼Œå‰‡è‘—é‡æè¿°æ­£é¢è©•åƒ¹ã€‚\n",
        "è«‹ä¸è¦è‡ªè¡Œç·¨é€ è©•è«–ä¸­æœªæåŠçš„å…§å®¹ï¼Œä¸¦å›ç­”è©•åƒ¹å…§å®¹éƒ¨åˆ†å°±å¥½ï¼Œå…¶ä»–å›æ‡‰ä¸éœ€è¦ï¼Œä¸¦ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚\n",
        "\n",
        "é¡§å®¢è©•è«–å¦‚ä¸‹ï¼š\n",
        "{reviews_str}\n",
        "\n",
        "å°ˆæ¥­è©•è«–ç¸½çµï¼š\"\"\"\n",
        "    summary = generate_llm_output(prompt_summary)\n",
        "\n",
        "    '''# 2. ç”Ÿæˆ AI é£Ÿè¨˜ç‰‡æ®µ (å‡è¨­æ¨¡ä»¿ä¸€ä½æ´»æ½‘çš„ç¾é£Ÿéƒ¨è½å®¢)\n",
        "    prompt_creative_review = f\"å‡è¨­ä½ æ˜¯ä¸€ä½æ´»æ½‘çš„ç¾é£Ÿéƒ¨è½å®¢ï¼Œè«‹æ ¹æ“šä»¥ä¸‹é¡§å®¢è©•è«–ï¼Œç‚ºé€™å®¶é¤å»³å¯«ä¸€æ®µç”Ÿå‹•æœ‰è¶£çš„é£Ÿè¨˜ç‰‡æ®µï¼ˆç´„80-120å­—ï¼Œç¹é«”ä¸­æ–‡ï¼‰ï¼Œè¦åŒ…å«ä¸€äº›æƒ…ç·’å’Œæ„Ÿå—ï¼š\\n\\n{reviews_str}\\n\\né£Ÿè¨˜ç‰‡æ®µï¼š\"\n",
        "    creative_review = generate_llm_output(prompt_creative_review)\n",
        "\n",
        "    # 3. æå–æ¨è–¦èœè‰² (ä¹Ÿå¯ä»¥ç”¨æ›´ç°¡å–®çš„é—œéµå­—æå–)\n",
        "    prompt_dishes = f\"å¾ä»¥ä¸‹é¡§å®¢è©•è«–ä¸­ï¼Œæå–å‡ºé¡§å®¢å€‘æ¨è–¦çš„èœè‰²åç¨± (å¦‚æœæœ‰çš„è©±ï¼Œè«‹åˆ—é»èªªæ˜ï¼Œç¹é«”ä¸­æ–‡)ï¼š\\n\\n{reviews_str}\\n\\næ¨è–¦èœè‰²ï¼š\"\n",
        "    dishes = generate_llm_output(prompt_dishes)'''\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "dDiBaKKtZQMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# å‡è¨­ä½ çš„ get_restaurant_reviews, analyze_reviews_with_llm (ç¾åœ¨åªè™•ç†ç¸½çµ),\n",
        "# AutoTokenizer, AutoModelForCausalLM, model, tokenizer ç­‰éƒ½å·²ç¶“åœ¨å‰é¢å®šç¾©å¥½äº†ã€‚\n",
        "\n",
        "# æˆ‘å‡è¨­ analyze_reviews_with_llm ç¾åœ¨ç¶“éä¿®æ”¹ï¼Œ\n",
        "# æˆ–è€…ä½ åªä½¿ç”¨å®ƒå›å‚³çš„ç¬¬ä¸€å€‹å€¼ä½œç‚ºç¸½çµã€‚\n",
        "# ä¾‹å¦‚ï¼Œå¦‚æœ analyze_reviews_with_llm åŸæœ¬è¿”å› (summary, creative, dishes)ï¼Œ\n",
        "# ä½ å¯ä»¥é€™æ¨£èª¿ç”¨ï¼š\n",
        "# llm_summary_text, _, _ = analyze_reviews_with_llm(restaurant_data['reviews_text'])\n",
        "# æˆ–è€…ï¼Œæ›´å¥½çš„æ–¹å¼æ˜¯ä¿®æ”¹ analyze_reviews_with_llm è®“å®ƒåªè¨ˆç®—ä¸¦è¿”å› summary_textã€‚\n",
        "# é€™è£¡ï¼Œæˆ‘å°‡å‡è¨­ analyze_reviews_with_llm åªè¿”å›ä¸€å€‹ç¸½çµå­—ä¸²ã€‚\n",
        "\n",
        "def gradio_interface(restaurant_name_input):\n",
        "    if not restaurant_name_input.strip():\n",
        "        # ä¿®æ”¹ï¼šéŒ¯èª¤æ™‚è¿”å› 3 å€‹å€¼\n",
        "        return \"éŒ¯èª¤ï¼šè«‹è¼¸å…¥é¤å»³åç¨±ã€‚\", \"\", \"\"\n",
        "\n",
        "    restaurant_data, error_msg = get_restaurant_reviews(restaurant_name_input)\n",
        "\n",
        "    if error_msg:\n",
        "        # ä¿®æ”¹ï¼šéŒ¯èª¤æ™‚è¿”å› 3 å€‹å€¼\n",
        "        return f\"éŒ¯èª¤ï¼š{error_msg}\", \"\", \"\"\n",
        "\n",
        "    if not restaurant_data:\n",
        "        # ä¿®æ”¹ï¼šéŒ¯èª¤æ™‚è¿”å› 3 å€‹å€¼\n",
        "        return \"éŒ¯èª¤ï¼šæœªèƒ½ç²å–é¤å»³è³‡è¨Šã€‚\", \"\", \"\"\n",
        "\n",
        "    # é¡¯ç¤ºåŸºæœ¬è³‡è¨Š\n",
        "    info_md = f\"\"\"\n",
        "    ### {restaurant_data['name']}\n",
        "    **åœ°å€ï¼š** {restaurant_data['address']}\n",
        "    **Google ç¸½é«”è©•åˆ†ï¼š** {restaurant_data['rating']} æ˜Ÿ\n",
        "    \"\"\"\n",
        "\n",
        "    raw_reviews_display = \"\\n\".join(restaurant_data['reviews_text']) if restaurant_data['reviews_text'] else \"æš«ç„¡è©•è«–å¯é¡¯ç¤ºã€‚\"\n",
        "\n",
        "    llm_summary_text = \"\" # åˆå§‹åŒ–\n",
        "    # ä½¿ç”¨ LLM è™•ç†è©•è«–\n",
        "    if not model or not tokenizer: # æª¢æŸ¥æ¨¡å‹æ˜¯å¦æˆåŠŸè¼‰å…¥\n",
        "        llm_summary_text = \"LLM æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚\"\n",
        "    elif not restaurant_data['reviews_text'] or \\\n",
        "         (restaurant_data['reviews_text'] and restaurant_data['reviews_text'][0] == \"æš«ç„¡è¶³å¤ çš„æ–‡å­—è©•è«–å¯ä¾›åˆ†æã€‚\"):\n",
        "        llm_summary_text = \"æ²’æœ‰è¶³å¤ çš„è©•è«–å…§å®¹å¯ä¾› LLM åˆ†æã€‚\"\n",
        "    else:\n",
        "        # å‡è¨­ analyze_reviews_with_llm ç¾åœ¨åªè² è²¬ç”Ÿæˆä¸¦è¿”å›ç¸½çµå­—ä¸²\n",
        "        # å¦‚æœå®ƒä¹‹å‰è¿”å›å¤šå€‹å€¼ï¼Œä½ éœ€è¦åƒé€™æ¨£èª¿æ•´ï¼š\n",
        "        # temp_summary, _, _ = analyze_reviews_with_llm(restaurant_data['reviews_text'])\n",
        "        # llm_summary_text = temp_summary\n",
        "        # ç‚ºäº†ç°¡æ½”ï¼Œæˆ‘å€‘å‡è¨­ analyze_reviews_with_llm å·²è¢«ä¿®æ”¹ç‚ºåªè¿”å›ç¸½çµ\n",
        "        llm_summary_text = analyze_reviews_with_llm(restaurant_data['reviews_text'])\n",
        "\n",
        "    # ä¿®æ”¹ï¼šåªè¿”å› 3 å€‹å€¼\n",
        "    return info_md, raw_reviews_display, llm_summary_text\n",
        "\n",
        "# å»ºç«‹ Gradio ä»‹é¢\n",
        "with gr.Blocks(title=\"AI ç¾é£Ÿè©•è«–å®¶\") as iface:\n",
        "    gr.Markdown(\"# ğŸœ AI ç¾é£Ÿè©•è«–å®¶ (å°åŒ—å¸‚å¤§å®‰å€)\")\n",
        "    gr.Markdown(\"è¼¸å…¥å¤§å®‰å€çš„é¤å»³åç¨±ï¼ŒAI å°‡å¾ Google Maps ç²å–è©•è«–ï¼Œä¸¦ç‚ºæ‚¨ç”Ÿæˆè©•è«–æ‘˜è¦ï¼\") # ä¿®æ”¹äº†æè¿°\n",
        "\n",
        "    restaurant_input = gr.Textbox(label=\"è«‹è¼¸å…¥é¤å»³åç¨± (é è¨­æœå°‹å°åŒ—å¸‚å¤§å®‰å€)\")\n",
        "    submit_button = gr.Button(\"æäº¤ï¼Œè®“ AI åˆ†æï¼\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    output_info = gr.Markdown(label=\"é¤å»³åŸºæœ¬è³‡è¨Š\")\n",
        "    output_raw_reviews = gr.Textbox(label=\"Google Maps åŸå§‹è©•è«–æ‘˜éŒ„ (æœ€å¤š5æ¢)\", lines=7, interactive=False)\n",
        "    output_summary = gr.Textbox(label=\"AI è©•è«–ç¸½çµ\", lines=4, interactive=False)\n",
        "\n",
        "    # ä»¥ä¸‹å…©å€‹ Textbox å·²è¢«åˆªé™¤\n",
        "    # output_creative = gr.Textbox(label=\"AI é¢¨æ ¼é£Ÿè¨˜ç‰‡æ®µ\", lines=6, interactive=False)\n",
        "    # output_dishes = gr.Textbox(label=\"AI æå–æ¨è–¦èœè‰²\", lines=3, interactive=False)\n",
        "\n",
        "    submit_button.click(\n",
        "        gradio_interface,\n",
        "        inputs=[restaurant_input],\n",
        "        # ä¿®æ”¹ï¼šoutputs åˆ—è¡¨åªåŒ…å« 3 å€‹å…ƒä»¶\n",
        "        outputs=[output_info, output_raw_reviews, output_summary]\n",
        "    )\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "Gv7XOpQl46zh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}