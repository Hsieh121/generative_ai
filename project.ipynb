{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hsieh121/generative_ai/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJDLUq9ZYoQF"
      },
      "outputs": [],
      "source": [
        "# Colab 程式碼儲存格\n",
        "!pip install googlemaps gradio transformers torch bitsandbytes accelerate # accelerate 可能對某些模型有幫助"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googlemaps\n",
        "from google.colab import userdata # 用於讀取 Colab Secrets\n",
        "\n",
        "# 從 Colab Secrets 讀取 API Key\n",
        "GMAPS_API_KEY = userdata.get('GMAPS_API_KEY') # 假設你將金鑰命名為 GMAPS_API_KEY\n",
        "gmaps = googlemaps.Client(key=GMAPS_API_KEY)\n",
        "\n",
        "def get_restaurant_reviews(restaurant_name, location=\"台北市大安區\"):\n",
        "    try:\n",
        "        # 1. Text Search (or Find Place) to get place_id\n",
        "        places_result = gmaps.places(query=f\"{restaurant_name} in {location}\")\n",
        "\n",
        "        if not places_result or places_result['status'] != 'OK' or not places_result['results']:\n",
        "            return None, \"找不到餐廳或API查詢失敗。\"\n",
        "\n",
        "        place_id = places_result['results'][0]['place_id'] # 取第一個結果\n",
        "        place_name_found = places_result['results'][0]['name']\n",
        "        place_address_found = places_result['results'][0].get('formatted_address', '地址未提供')\n",
        "        place_rating_found = places_result['results'][0].get('rating', '評分未提供')\n",
        "\n",
        "        # 2. Place Details to get reviews\n",
        "        # language='zh-TW' 嘗試獲取繁體中文評論\n",
        "        details = gmaps.place(place_id=place_id, fields=['name', 'formatted_address', 'rating', 'reviews'], language='zh-TW')\n",
        "\n",
        "        if details['status'] != 'OK':\n",
        "            return None, \"獲取餐廳詳細資訊失敗。\"\n",
        "\n",
        "        restaurant_info = {\n",
        "            \"name\": details['result'].get('name', place_name_found),\n",
        "            \"address\": details['result'].get('formatted_address', place_address_found),\n",
        "            \"rating\": details['result'].get('rating', place_rating_found),\n",
        "            \"reviews_text\": []\n",
        "        }\n",
        "\n",
        "        # Places API 通常返回最多 5 條評論\n",
        "        if 'reviews' in details['result']:\n",
        "            for review in details['result']['reviews']:\n",
        "                restaurant_info[\"reviews_text\"].append(f\"- {review.get('author_name', '匿名使用者')} (評分: {review.get('rating', 'N/A')}星): {review.get('text', '')}\")\n",
        "\n",
        "        if not restaurant_info[\"reviews_text\"]:\n",
        "             restaurant_info[\"reviews_text\"].append(\"暫無足夠的文字評論可供分析。\")\n",
        "\n",
        "        return restaurant_info, None\n",
        "    except Exception as e:\n",
        "        return None, f\"發生錯誤：{str(e)}\""
      ],
      "metadata": {
        "id": "yFMnRGXyY4Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig # 引入 BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# --- 你要載入的模型 ID ---\n",
        "model_id = \"google/gemma-7b-it\" # Gemma 7B (需要處理授權和 HuggingFace Token)\n",
        "\n",
        "model = None  # 先初始化為 None\n",
        "tokenizer = None # 先初始化為 None\n",
        "\n",
        "try:\n",
        "    print(f\"準備載入【4-bit 量化】模型: {model_id}\")\n",
        "    print(f\"檢查 CUDA 是否可用: {torch.cuda.is_available()}\") # 確認 CUDA 環境\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    # --- 設定 4-bit 量化配置 ---\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",                # 指定量化類型，\"nf4\" (NormalFloat4) 是常用的選擇\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,    # 設定計算時使用的資料類型，bfloat16 可提升效能\n",
        "                                                  # 如果你的 GPU 對 bfloat16 支援不佳，可以改用 torch.float16\n",
        "        bnb_4bit_use_double_quant=False           # 是否使用雙重量化，通常設為 False 即可\n",
        "    )\n",
        "\n",
        "    # --- 載入量化模型 ---\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=quantization_config, # <--- 傳入量化設定\n",
        "        device_map=\"auto\"                        # <--- 讓 Transformers 自動分配到 GPU (如果可用)\n",
        "    )\n",
        "    print(f\"【4-bit 量化】模型 {model_id} 已載入到設備: {model.device}\")\n",
        "    if hasattr(model, 'get_memory_footprint'): # 檢查模型物件是否有 get_memory_footprint 方法\n",
        "        print(f\"模型記憶體佔用 (近似): {model.get_memory_footprint() / 1024**3:.2f} GB\") # 量化後應遠小於 14GB\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"載入【4-bit 量化】模型 {model_id} 時發生錯誤 (可能是資源不足、需要授權、模型名稱錯誤或 bitsandbytes 未正確安裝/版本過舊): {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc() # 打印詳細的錯誤堆疊"
      ],
      "metadata": {
        "id": "8Wfe6p4hAKIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llm_output(prompt_text):\n",
        "    if not model or not tokenizer:\n",
        "        return \"LLM 模型未能成功載入，無法生成文字。\"\n",
        "    try:\n",
        "        inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device) # 將輸入移至模型所在的設備\n",
        "        outputs = model.generate(**inputs, max_new_tokens=250, pad_token_id=tokenizer.eos_token_id) # pad_token_id 避免警告\n",
        "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        #print(f\"DEBUG generate_llm_output: Full decoded result before processing: {result}\") # <--- 新增\n",
        "        # Gemma 模型的回應可能包含原始 prompt，需要處理\n",
        "        # 簡單的處理方式是移除 prompt_text 的部分\n",
        "        if result.startswith(prompt_text):\n",
        "             return result[len(prompt_text):].strip()\n",
        "        return result.strip() # 確保移除前後空白\n",
        "    except Exception as e:\n",
        "        return f\"LLM 生成時發生錯誤：{str(e)}\"\n",
        "\n",
        "def analyze_reviews_with_llm(reviews_list):\n",
        "    reviews_str = \"\\n\".join(reviews_list)\n",
        "\n",
        "    # 1. 評論總結\n",
        "    prompt_summary = f\"\"\"作為一個客觀的美食評論分析員，請仔細閱讀以下顧客評論。\n",
        "根據這些評論，請用繁體中文為這家餐廳寫一段精簡的整體評價總結，字數約200字（繁體中文）。\n",
        "總結應涵蓋顧客提及的主要正面和負面體驗，如果沒有明顯的負面體驗，則著重描述正面評價。\n",
        "請不要自行編造評論中未提及的內容，並回答評價內容部分就好，其他回應不需要，並翻譯成繁體中文。\n",
        "\n",
        "顧客評論如下：\n",
        "{reviews_str}\n",
        "\n",
        "專業評論總結：\"\"\"\n",
        "    summary = generate_llm_output(prompt_summary)\n",
        "\n",
        "    '''# 2. 生成 AI 食記片段 (假設模仿一位活潑的美食部落客)\n",
        "    prompt_creative_review = f\"假設你是一位活潑的美食部落客，請根據以下顧客評論，為這家餐廳寫一段生動有趣的食記片段（約80-120字，繁體中文），要包含一些情緒和感受：\\n\\n{reviews_str}\\n\\n食記片段：\"\n",
        "    creative_review = generate_llm_output(prompt_creative_review)\n",
        "\n",
        "    # 3. 提取推薦菜色 (也可以用更簡單的關鍵字提取)\n",
        "    prompt_dishes = f\"從以下顧客評論中，提取出顧客們推薦的菜色名稱 (如果有的話，請列點說明，繁體中文)：\\n\\n{reviews_str}\\n\\n推薦菜色：\"\n",
        "    dishes = generate_llm_output(prompt_dishes)'''\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "dDiBaKKtZQMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# 假設你的 get_restaurant_reviews, analyze_reviews_with_llm (現在只處理總結),\n",
        "# AutoTokenizer, AutoModelForCausalLM, model, tokenizer 等都已經在前面定義好了。\n",
        "\n",
        "# 我假設 analyze_reviews_with_llm 現在經過修改，\n",
        "# 或者你只使用它回傳的第一個值作為總結。\n",
        "# 例如，如果 analyze_reviews_with_llm 原本返回 (summary, creative, dishes)，\n",
        "# 你可以這樣調用：\n",
        "# llm_summary_text, _, _ = analyze_reviews_with_llm(restaurant_data['reviews_text'])\n",
        "# 或者，更好的方式是修改 analyze_reviews_with_llm 讓它只計算並返回 summary_text。\n",
        "# 這裡，我將假設 analyze_reviews_with_llm 只返回一個總結字串。\n",
        "\n",
        "def gradio_interface(restaurant_name_input):\n",
        "    if not restaurant_name_input.strip():\n",
        "        # 修改：錯誤時返回 3 個值\n",
        "        return \"錯誤：請輸入餐廳名稱。\", \"\", \"\"\n",
        "\n",
        "    restaurant_data, error_msg = get_restaurant_reviews(restaurant_name_input)\n",
        "\n",
        "    if error_msg:\n",
        "        # 修改：錯誤時返回 3 個值\n",
        "        return f\"錯誤：{error_msg}\", \"\", \"\"\n",
        "\n",
        "    if not restaurant_data:\n",
        "        # 修改：錯誤時返回 3 個值\n",
        "        return \"錯誤：未能獲取餐廳資訊。\", \"\", \"\"\n",
        "\n",
        "    # 顯示基本資訊\n",
        "    info_md = f\"\"\"\n",
        "    ### {restaurant_data['name']}\n",
        "    **地址：** {restaurant_data['address']}\n",
        "    **Google 總體評分：** {restaurant_data['rating']} 星\n",
        "    \"\"\"\n",
        "\n",
        "    raw_reviews_display = \"\\n\".join(restaurant_data['reviews_text']) if restaurant_data['reviews_text'] else \"暫無評論可顯示。\"\n",
        "\n",
        "    llm_summary_text = \"\" # 初始化\n",
        "    # 使用 LLM 處理評論\n",
        "    if not model or not tokenizer: # 檢查模型是否成功載入\n",
        "        llm_summary_text = \"LLM 模型未能成功載入，無法進行分析。\"\n",
        "    elif not restaurant_data['reviews_text'] or \\\n",
        "         (restaurant_data['reviews_text'] and restaurant_data['reviews_text'][0] == \"暫無足夠的文字評論可供分析。\"):\n",
        "        llm_summary_text = \"沒有足夠的評論內容可供 LLM 分析。\"\n",
        "    else:\n",
        "        # 假設 analyze_reviews_with_llm 現在只負責生成並返回總結字串\n",
        "        # 如果它之前返回多個值，你需要像這樣調整：\n",
        "        # temp_summary, _, _ = analyze_reviews_with_llm(restaurant_data['reviews_text'])\n",
        "        # llm_summary_text = temp_summary\n",
        "        # 為了簡潔，我們假設 analyze_reviews_with_llm 已被修改為只返回總結\n",
        "        llm_summary_text = analyze_reviews_with_llm(restaurant_data['reviews_text'])\n",
        "\n",
        "    # 修改：只返回 3 個值\n",
        "    return info_md, raw_reviews_display, llm_summary_text\n",
        "\n",
        "# 建立 Gradio 介面\n",
        "with gr.Blocks(title=\"AI 美食評論家\") as iface:\n",
        "    gr.Markdown(\"# 🍜 AI 美食評論家 (台北市大安區)\")\n",
        "    gr.Markdown(\"輸入大安區的餐廳名稱，AI 將從 Google Maps 獲取評論，並為您生成評論摘要！\") # 修改了描述\n",
        "\n",
        "    restaurant_input = gr.Textbox(label=\"請輸入餐廳名稱 (預設搜尋台北市大安區)\")\n",
        "    submit_button = gr.Button(\"提交，讓 AI 分析！\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    output_info = gr.Markdown(label=\"餐廳基本資訊\")\n",
        "    output_raw_reviews = gr.Textbox(label=\"Google Maps 原始評論摘錄 (最多5條)\", lines=7, interactive=False)\n",
        "    output_summary = gr.Textbox(label=\"AI 評論總結\", lines=4, interactive=False)\n",
        "\n",
        "    # 以下兩個 Textbox 已被刪除\n",
        "    # output_creative = gr.Textbox(label=\"AI 風格食記片段\", lines=6, interactive=False)\n",
        "    # output_dishes = gr.Textbox(label=\"AI 提取推薦菜色\", lines=3, interactive=False)\n",
        "\n",
        "    submit_button.click(\n",
        "        gradio_interface,\n",
        "        inputs=[restaurant_input],\n",
        "        # 修改：outputs 列表只包含 3 個元件\n",
        "        outputs=[output_info, output_raw_reviews, output_summary]\n",
        "    )\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "Gv7XOpQl46zh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}