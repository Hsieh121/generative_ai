{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hsieh121/generative_ai/blob/main/HW10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxCcNOPBCmf2"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate safetensors huggingface_hub gradio --upgrade\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, UniPCMultistepScheduler\n",
        "import torch\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "import random\n",
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4fEdszfCyO7"
      },
      "outputs": [],
      "source": [
        "model_name = \"stablediffusionapi/sdvn5-3dcutewave\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    #use_safetensors=True\n",
        ").to(\"cuda\")\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpPjwVKbDEKe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import random\n",
        "import gc\n",
        "import os\n",
        "\n",
        "# å‡è¨­åœ¨æŸè™•ç²å– API é‡‘é‘°\n",
        "api_key = userdata.get('Groq')  # æˆ–è€…æ˜¯ç›´æ¥è¨­å®š 'ä½ çš„APIé‡‘é‘°'\n",
        "os.environ['GROQ_API_KEY'] = api_key  # å¯é¸ï¼Œé€™æ¨£è¨­å®šå¾Œå…¶ä»–ç¨‹å¼å¯ä»¥ç”¨é€™å€‹ç’°å¢ƒè®Šæ•¸\n",
        "\n",
        "def translate_prompt_with_groq(prompt_zh, Groq):\n",
        "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {Groq}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"model\": \"llama3-70b-8192\",  # æˆ–è€…å…¶ä»–ä½ éœ€è¦ä½¿ç”¨çš„æ¨¡å‹\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"ä½ æ˜¯ä¸€ä½å°ˆæ¥­å¯æ„›3Dç«‹é«”è§’è‰²åœ–ç‰‡ç”Ÿæˆæç¤ºè©è¨­è¨ˆå¸«ï¼Œè«‹å°‡ä½¿ç”¨è€…æä¾›çš„ prompt çµåˆå¯æ„›3Dç«‹é«”çš„é¢¨æ ¼ï¼Œä¸¦ç¿»è­¯æˆç²¾æº–ä¸”é©åˆ Stable Diffusion ä½¿ç”¨çš„è‹±æ–‡ promptï¼Œä¿ç•™é¢¨æ ¼èˆ‡ç´°ç¯€æè¿°ã€‚\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt_zh\n",
        "            }\n",
        "        ],\n",
        "        \"temperature\": 0.3\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()  # è‹¥ç‹€æ…‹ç¢¼ä¸æ˜¯ 2xx æœƒæ‹‹å‡ºç•°å¸¸\n",
        "        result = response.json()\n",
        "        return result['choices'][0]['message']['content'].strip()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"[éŒ¯èª¤] è«‹æ±‚å¤±æ•—: {e}\")\n",
        "        return prompt_zh  # å¦‚æœ API è«‹æ±‚å¤±æ•—ï¼Œè¿”å›åŸå§‹ä¸­æ–‡ prompt\n",
        "\n",
        "def generate_images(prompt, use_enhance, enhance_text, use_negative, negative_text,\n",
        "                    use_custom_seed, custom_seed, height, width, steps, num_images):\n",
        "\n",
        "    height = int(height)\n",
        "    width = int(width)\n",
        "\n",
        "    if height % 8 != 0 or width % 8 != 0:\n",
        "        raise ValueError(\"é«˜åº¦å’Œå¯¬åº¦å¿…é ˆæ˜¯8çš„å€æ•¸ï¼\")\n",
        "\n",
        "    if use_custom_seed:\n",
        "        base_seed = int(custom_seed)\n",
        "    else:\n",
        "        base_seed = random.randint(0, 2**32 - 1)\n",
        "\n",
        "    seeds = [base_seed + i for i in range(num_images)]\n",
        "\n",
        "    # ç¿»è­¯æ­£é¢ promptï¼ˆå¦‚æœæ˜¯ä¸­æ–‡è€Œä¸”æä¾›äº† Groq API Keyï¼‰\n",
        "    final_prompt = prompt\n",
        "    if api_key:  # ç¢ºä¿æä¾›äº† API Key\n",
        "        try:\n",
        "            final_prompt = translate_prompt_with_groq(prompt, api_key)\n",
        "        except Exception as e:\n",
        "            print(f\"[è­¦å‘Š] ç¿»è­¯å¤±æ•—ï¼Œå°‡ä½¿ç”¨åŸå§‹ prompt: {e}\")\n",
        "\n",
        "    if use_enhance and enhance_text:\n",
        "        final_prompt += \", \" + enhance_text\n",
        "\n",
        "    final_negative = negative_text if use_negative else None\n",
        "\n",
        "    prompts = [final_prompt] * num_images\n",
        "    negative_prompts = [final_negative] * num_images\n",
        "    generators = [torch.Generator(\"cuda\").manual_seed(seed) for seed in seeds]\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    images = []\n",
        "    for i in range(num_images):\n",
        "        with torch.no_grad():\n",
        "            image = pipe(\n",
        "                prompt=prompts[i],\n",
        "                negative_prompt=negative_prompts[i] if final_negative else None,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_inference_steps=steps,\n",
        "                guidance_scale=7.5,\n",
        "                generator=generators[i]\n",
        "            ).images[0]\n",
        "            images.append(image)\n",
        "\n",
        "    return images, f\"ä½¿ç”¨çš„ random seeds: {seeds}\"\n",
        "print(api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uJnUGTXDOCN"
      },
      "outputs": [],
      "source": [
        "default_enhance = \"cute chibi character, 3D style, pastel colors, big sparkling eyes, soft lighting, smooth shading, toy-like textures, highly detailed, adorable proportions, cinematic render, Pixar-style, high resolution, vibrant colors\"\n",
        "default_negative = \"ugly, deformed, low quality, blurry, grainy, out of frame, bad anatomy, extra limbs, distorted face, bad proportions, glitch, text, watermark, signature, low resolution, mutated hands, extra fingers, poorly drawn\"\n",
        "\n",
        "with gr.Blocks(css=\".gradio-container {background-color: #FAFAFA; padding: 20px;} .gr-button {font-size: 18px; background: linear-gradient(to right, #667eea, #764ba2); color: white;}\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ğŸ¨ è§’è‰²ç”Ÿæˆå™¨\n",
        "    æ­¡è¿ä½¿ç”¨ï¼è¼¸å…¥æç¤ºè©ã€é¸æ“‡è¨­å®šï¼Œç«‹å³ç”Ÿæˆä½ çš„3Då¯æ„›é¢¨æ ¼çš„è§’è‰²ï¼\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=6):\n",
        "            prompt = gr.Textbox(label=\"Prompt\", placeholder=\"è«‹è¼¸å…¥ä½ çš„æç¤ºè© (prompt)\", lines=3)\n",
        "            with gr.Row():\n",
        "                use_enhance = gr.Checkbox(label=\"åŠ å¼· Prompt\", value=True)\n",
        "                enhance_text = gr.Textbox(label=\"åŠ å¼·å…§å®¹\", value=default_enhance)\n",
        "            with gr.Row():\n",
        "                use_negative = gr.Checkbox(label=\"ä½¿ç”¨ Negative Prompt\", value=True)\n",
        "                negative_text = gr.Textbox(label=\"Negative Prompt å…§å®¹\", value=default_negative)\n",
        "            with gr.Row():\n",
        "                use_custom_seed = gr.Checkbox(label=\"è‡ªè¨‚ Random Seed\", value=False)\n",
        "                custom_seed = gr.Number(label=\"æŒ‡å®š seed (é¸å¡«)\", value=42)\n",
        "            with gr.Row():\n",
        "                height = gr.Dropdown([\"512\", \"768\", \"1024\"], label=\"é«˜åº¦ Height\", value=\"512\")\n",
        "                width = gr.Dropdown([\"512\", \"768\", \"1024\"], label=\"å¯¬åº¦ Width\", value=\"512\")\n",
        "            with gr.Row():\n",
        "                steps = gr.Slider(10, 100, value=20, step=5, label=\"ç”Ÿæˆæ­¥æ•¸ (Steps)\")\n",
        "                num_images = gr.Slider(1, 4, step=1, value=1, label=\"ç”Ÿæˆå¼µæ•¸\")\n",
        "            generate_btn = gr.Button(\"ğŸš€ é–‹å§‹ç”Ÿæˆï¼\")\n",
        "\n",
        "        with gr.Column(scale=6):\n",
        "            gallery = gr.Gallery(label=\"ç”Ÿæˆçµæœ\", columns=2, object_fit=\"contain\", height=\"auto\")\n",
        "            seed_info = gr.Label(label=\"ä½¿ç”¨çš„ Random Seeds\")\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=generate_images,\n",
        "        inputs=[prompt, use_enhance, enhance_text, use_negative, negative_text,\n",
        "                use_custom_seed, custom_seed, height, width, steps, num_images],\n",
        "        outputs=[gallery, seed_info]\n",
        "    )\n",
        "\n",
        "    demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}